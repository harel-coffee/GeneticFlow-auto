139513906,MULTIMODAL INTERFACES THAT Flex Adapt and Persist,2004,0,118,2,0.0,2034196114,Myron D. Flickner,0,0.016357069610664,0.0645642369777481
179083188,Modeling interactive agents in ALIVE,1995,3,8,3,0.0,2650378090,Pattie Maes,0,0.016357069610664,0.0645642369777481
225486887,Proceedings of the 6th International Conference on Multimodal Interfaces ICMI 2004 State College PA USA October 13-15 2004,2004,0,0,3,0.0,2095094870,Gianni Lazzari,0,0.016357069610664,0.0645642369777481
32356151,Information-theoretic fusion for multimodal interfaces,2002,10,0,1,1.0,2174985400,Trevor Darrell,0,0.016357069610664,0.0645642369777481
1893774647,Method and system for facilitating wireless full-body real-time user interaction with a digitally represented visual environment,1994,22,415,4,0.0,1967546095,Alex Pentland,0,-0.2517174508338541,-0.24012202389667436
1964067440,Gesture + play full-body interaction for virtual environments,2003,3,27,3,0.0,2230601179,Tollmar Konrad,0,1.1582699686068616,0.28131071180027906
1965674632,Invited talk image recognition for intelligent interfaces,2009,0,0,1,1.0,2174985400,Trevor Darrell,0,-0.36392477096384696,-0.5565834300923171
2001538864,Guest Editors Introduction to the Special Issue on Domain Adaptation for Vision Applications,2014,0,13,3,0.0,2425744831,Dong Xu,0,0.016357069610664,0.0645642369777481
2012714714,IDeixis image-based Deixis for finding location-based information,2004,18,32,3,1.0,2104162850,Tom Yeh,0,0.016357069610664,0.0645642369777481
2068365609,Nodding in conversations with a robot,2004,4,16,6,0.0,2568481091,Christopher Lee,0,0.36243451127494414,0.6188231810624156
2066787496,Towards adaptive object recognition for situated human-computer interaction,2007,8,7,2,0.0,1580821723,Kate Saenko,0,0.36243451127494414,0.6188231810624156
2067177358,Evaluating look-to-talk a gaze-aware interface in a collaborative environment,2002,7,70,7,0.0,2695422228,Alice Oh,0,-0.17684561708418714,0.33448707808304967
2093094406,Detecting communication errors from visual cues during the systems conversational turn,2007,18,1,3,0.0,2171903504,Sy Bor Wang,0,0.016357069610664,0.0645642369777481
2080932187,Interactive adaptation of real-time object detectors,2014,30,14,5,0.0,2546940624,Daniel Goehring,0,0.016357069610664,0.0645642369777481
2100824973,Activity Zones for Context-Aware Computing,2003,35,100,5,0.0,410361343,Kimberle Koile,0,-0.2540425979235508,0.4466652765137865
2084743543,Multimodal question answering for mobile devices,2008,5,10,2,1.0,2104162850,Tom Yeh,0,0.016357069610664,0.0645642369777481
2104146451,Towards Context-Based Visual Feedback Recognition for Embodied Agents,2005,12,5,2,1.0,2055927854,Louis Philippe Morency,0,0.36243451127494414,0.6188231810624156
2083235550,Navigating in virtual environments using a vision-based interface,2004,23,10,3,0.0,2283826149,Konrad Tollmar,0,1.0470290186188798,1.0160178814415604
2126544293,Face-Responsive Interfaces From Direct Manipulation to Perceptive Presence,2002,33,19,1,1.0,2174985400,Trevor Darrell,0,-0.09357759011525085,-0.30781735444982655
2138541441,From conversational tooltips to grounded discourse head poseTracking in interactive dialog systems,2004,25,14,2,1.0,2055927854,Louis Philippe Morency,0,0.1036876261341461,0.1761527275361874
2106239555,The ALIVE system full-body interaction with autonomous agents,1995,11,152,2,0.0,2650378090,Pattie Maes,0,0.21761226538854453,-0.3035664487846248
2112618815,Contextual recognition of head gestures,2005,17,119,4,1.0,2055927854,Louis Philippe Morency,0,0.681176284320039,1.2391639166494575
2106687443,3-D articulated pose tracking for untethered diectic reference,2002,18,50,2,1.0,405353000,David Demirdjian,0,0.19693676282751169,0.45555950921296895
2113123608,Recognizing gaze aversion gestures in embodied conversational discourse,2006,35,45,3,0.9375,2055927854,Louis Philippe Morency,0,-0.13030495496334374,0.5264285991989638
2113615789,Head gesture recognition in intelligent interfaces the role of context in improving recognition,2006,20,63,2,0.9375,2055927854,Louis Philippe Morency,0,0.6522871472563974,1.2175806023824265
2107947143,Using robotic exploratory procedures to learn the meaning of haptic adjectives,2013,19,73,10,0.0,2470793057,Vivian Chu,0,0.42798208983122954,0.4620703331899103
2164832065,A novel environment for situated vision and behavior,1996,17,39,2,0.75,1967546095,Alex Pentland,0,0.15662054649494686,0.9077026449997398
2293023258,Perceptive presence,2003,20,13,5,0.0,2150651876,Frank Bentley,0,-1.0033913173558222,-1.4399815437265504
2491082481,Introduction to the CVIU special issue on Parts and Attributes,2015,0,1,3,0.0,206624101,Vincent Lepetit,0,0.016357069610664,0.0645642369777481
2495381759,A novel environment for situated vision and behavior,1994,0,37,2,0.0,1967546095,Alex Pentland,0,0.016357069610664,0.0645642369777481
2805984364,Speaker-Follower Models for Vision-and-Language Navigation,2018,52,22,10,1.0,2104954252,Daniel Fried,0,0.016357069610664,0.0645642369777481
2799244840,Fooling Vision and Language Models Despite Localization and Attention Mechanism,2018,71,14,5,1.0,2747775172,Xiaojun Xu,0,0.016357069610664,0.0645642369777481
2786487443,Zero-Shot Visual Imitation,2018,31,70,10,0.0,2135830645,Deepak Pathak,0,0.016357069610664,0.0645642369777481
2885138528,Textual Explanations for Self-Driving Vehicles,2018,30,37,3,0.0,2902040111,Jinkyu Kim,0,0.016357069610664,0.0645642369777481
2908470496,Zero-Shot Visual Imitation,2018,0,45,8,0.0,2135830645,Deepak Pathak,0,0.016357069610664,0.0645642369777481
2912410476,Adapting to Continuously Shifting Domains,2018,0,7,4,0.0,2912587892,Andreea Bobu,0,0.016357069610664,0.0645642369777481
2950176936,Fooling Vision and Language Models Despite Localization and Attention Mechanism,2017,62,12,5,1.0,2747775172,Xiaojun Xu,0,0.016357069610664,0.0645642369777481
2952373945,Visual Discovery at Pinterest,2017,34,3,8,0.0,2223739488,Andrew Zhai,0,-0.36392477096384696,-0.5565834300923171
2952826823,Textual Explanations for Self-Driving Vehicles,2018,22,0,3,0.0,2902040111,Jinkyu Kim,0,0.016357069610664,0.0645642369777481
2963654998,Deep learning for tactile understanding from visual and haptic data,2016,36,85,4,0.0,2992037913,Yang Gao,0,0.42798208983122954,0.4620703331899103
2963689319,Deep Object-Centric Representations for Generalizable Robot Learning,2018,0,26,3,1.0,2549226862,Coline Devin,0,0.19273499667151017,0.3149483151666419
2963726321,Speaker-Follower Models for Vision-and-Language Navigation,2018,0,39,10,1.0,2104954252,Daniel Fried,0,0.016357069610664,0.0645642369777481
2964021598,Zero-Shot Visual Imitation,2018,22,25,9,0.0,2135830645,Deepak Pathak,0,0.19273499667151017,0.3149483151666419
2964262254,Learning modular neural network policies for multi-task and multi-robot transfer,2017,34,90,3,1.0,2549226862,Coline Devin,0,0.016357069610664,0.0645642369777481
2964343989,Are You Looking Grounding to Multiple Modalities in Vision-and-Language Navigation,2019,0,2,5,1.0,2234353460,Ronghang Hu,0,0.016357069610664,0.0645642369777481
2989781232,ICMI03 Fifth International Conference on Multimodal Interfaces Preface,2003,0,0,3,0.0,565358538,Wolfgang Wahlster,0,0.016357069610664,0.0645642369777481
