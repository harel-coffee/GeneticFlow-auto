2021.spnlp-1.5,Mode recovery in neural autoregressive sequence modeling,2021,-1,-1,3,1,1030,ilia kulikov,Proceedings of the 5th Workshop on Structured Prediction for NLP (SPNLP 2021),0,0,0.0,0.0
2021.mrl-1.13,{V}isual{S}em: a high-quality knowledge graph for vision and language,2021,-1,-1,5,0,5217,houda alberts,Proceedings of the 1st Workshop on Multilingual Representation Learning,0,0,0.0,0.0
2021.emnlp-main.422,The Future is not One-dimensional: Complex Event Schema Induction by Graph Modeling for Event Prediction,2021,-1,-1,5,0,714,manling li,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,0,0.0,0.0
2021.eacl-main.39,{A}dapter{F}usion: Non-Destructive Task Composition for Transfer Learning,2021,-1,-1,4,0,7438,jonas pfeiffer,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,0,0.0,0.0
2021.eacl-main.95,Analyzing the Forgetting Problem in Pretrain-Finetuning of Open-domain Dialogue Response Models,2021,-1,-1,3,0,9563,tianxing he,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,0,0.0,0.0
2021.acl-long.92,Comparing Test Sets with Item Response Theory,2021,-1,-1,8,0,1381,clara vania,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,0,0.0,0.0
2021.acl-long.508,"Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search",2021,-1,-1,2,0,8193,gyuwan kim,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,0,0.0,0.0
2020.spnlp-1.10,On the Discrepancy between Density Estimation and Sequence Generation,2020,-1,-1,4,1,10266,jason lee,Proceedings of the Fourth Workshop on Structured Prediction for NLP,0,0,0.0,0.0
2020.spnlp-1.11,Log-Linear Reformulation of the Noisy Channel Model for Document-Level Neural Machine Translation,2020,-1,-1,2,1,14551,sebastien jean,Proceedings of the Fourth Workshop on Structured Prediction for NLP,0,0,0.0,0.0
2020.sdp-1.5,Covidex: Neural Ranking Models and Keyword Search Infrastructure for the {COVID}-19 Open Research Dataset,2020,-1,-1,9,0,15416,edwin zhang,Proceedings of the First Workshop on Scholarly Document Processing,0,0,0.0,0.0
2020.repl4nlp-1.5,Compositionality and Capacity in Emergent Languages,2020,-1,-1,5,0,15633,abhinav gupta,Proceedings of the 5th Workshop on Representation Learning for NLP,0,0,0.0,0.0
2020.nlpcovid19-acl.2,Rapidly Deploying a Neural Search Engine for the {COVID-19} {Open} {Research} {Dataset},2020,27,3,4,0,15416,edwin zhang,Proceedings of the 1st Workshop on {NLP} for {COVID-19} at {ACL} 2020,0,0,0.0,0.0
2020.emnlp-main.50,Connecting the Dots: Event Graph Schema Induction with Path Language Modeling,2020,-1,-1,4,0,714,manling li,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,0.0,0.0
2020.emnlp-main.73,Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation,2020,-1,-1,3,1,10266,jason lee,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,0.0,0.0
2020.emnlp-main.97,{SSMBA}: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness,2020,-1,-1,2,0,20139,nathan ng,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,0.0,0.0
2020.emnlp-main.448,Consistency of a Recurrent Language Model With Respect to Incomplete Decoding,2020,-1,-1,5,1,1031,sean welleck,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,0.0,0.0
2020.emnlp-main.713,Unsupervised Question Decomposition for Question Answering,2020,41,4,4,0,10149,ethan perez,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,-0.2943849466263354,-0.35158901592655745
2020.emnlp-demos.7,{A}dapter{H}ub: A Framework for Adapting Transformers,2020,-1,-1,7,0,7438,jonas pfeiffer,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,0,0,0.0,0.0
2020.eamt-1.22,Learning Non-Monotonic Automatic Post-Editing of Translations from Human Orderings,2020,26,0,2,0,20842,antonio gois,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,0,0.27751574528465023,-0.008393373024748333
2020.coling-main.230,Improving Conversational Question Answering Systems after Deployment using Feedback-Weighted Learning,2020,-1,-1,2,0,16265,jon campos,Proceedings of the 28th International Conference on Computational Linguistics,0,0,0.0,0.0
2020.acl-main.428,Don{'}t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training,2020,-1,-1,6,0,3430,margaret li,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,0,0.0,0.0
2020.acl-main.450,Asking and Answering Questions to Evaluate the Factual Consistency of Summaries,2020,40,2,2,0,9746,alex wang,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,0,-0.1787956355762268,-0.39666807626292166
2020.aacl-main.36,A Systematic Characterization of Sampling Algorithms for Open-ended Language Generation,2020,-1,-1,3,0,6259,moin nadeem,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,0,0,0.0,0.0
W19-8609,Importance of Search and Evaluation Strategies in Neural Dialogue Modeling,2019,0,3,3,1,1030,ilia kulikov,Proceedings of the 12th International Conference on Natural Language Generation,0,0,-0.031362483355824,-0.032453646393453
W19-3620,Non-Monotonic Sequential Text Generation,2019,64,16,2,0,22687,kiante brantley,Proceedings of the 2019 Workshop on Widening NLP,0,0,-0.3331380748999089,0.12138488301712635
W19-2304,"{BERT} has a Mouth, and It Must Speak: {BERT} as a {M}arkov Random Field Language Model",2019,23,36,2,0,9746,alex wang,Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation,0,0,-0.05600143163418515,-0.07450354818285555
R19-1153,Sequential Graph Dependency Parser,2019,0,0,2,1,1031,sean welleck,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,0,1.054435720012476,-0.5433854697590983
Q19-1042,Insertion-based Decoding with Automatically Inferred Generation Order,2019,52,7,3,1,7512,jiatao gu,Transactions of the Association for Computational Linguistics,0,0,1.4025805666846969,-0.376595974511922
P19-1121,Improved Zero-shot Neural Machine Translation via Ignoring Spurious Correlations,2019,27,7,3,1,7512,jiatao gu,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,0,0.059075870775379846,-0.4249569346479556
P19-1177,Generating Diverse Translations with Sentence Codes,2019,0,4,3,0,5994,raphael shu,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,0,0.2776337335288787,-0.19511070700392805
P19-1363,Dialogue Natural Language Inference,2019,0,11,4,1,1031,sean welleck,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,0,0.9516455680856496,0.4734218239228285
D19-6123,Neural Unsupervised Parsing Beyond {E}nglish,2019,0,1,4,0,1310,katharina kann,Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019),0,0,0.23185760743802142,-0.3886521694675594
D19-1244,Finding Generalizable Evidence by Learning to Convince {Q}{\\&}{A} Models,2019,0,4,6,0,10149,ethan perez,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,-0.031362483355824,-0.032453646393453
D19-1329,Towards Realistic Practices In Low-Resource Natural Language Processing: The Development Set,2019,0,0,2,0,1310,katharina kann,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,-0.031362483355824,-0.032453646393453
D19-1384,Emergent Linguistic Phenomena in Multi-Agent Communication Games,2019,46,6,2,0,26993,laura graesser,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,0.3888248034968611,-0.5201171810011487
D19-1447,Countering Language Drift via Visual Grounding,2019,45,1,2,1,10266,jason lee,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,0.34682220560644805,-0.24206476729642595
W18-5407,Jump to better conclusions: {SCAN} both left and right,2018,16,1,4,0,10758,jasmijn bastings,Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP},0,0,0.0,0.0
W18-5452,Grammar Induction with Neural Language Models: An Unusual Replication,2018,0,14,2,0,12837,phu htut,Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP},0,0,0.3089085751024246,-0.8413303251870011
W18-3221,Code-Switched Named Entity Recognition with Embedding Attention,2018,0,7,2,0,5717,changhan wang,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,0,-0.05302067682117545,0.0896451735666221
P18-1201,Zero-Shot Transfer Learning for Event Extraction,2018,0,11,3,0,9579,lifu huang,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,0,-0.031362483355824,-0.032453646393453
N18-4017,Training a Ranking Function for Open-Domain Question Answering,2018,8,2,3,0,12837,phu htut,Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Student Research Workshop,0,0,-0.5114375688534496,-0.6825933866913105
K18-3006,The {NYU} System for the {C}o{NLL}{--}{SIGMORPHON} 2018 Shared Task on Universal Morphological Reinflection,2018,-1,-1,3,0,1310,katharina kann,Proceedings of the {C}o{NLL}{--}{SIGMORPHON} 2018 Shared Task: Universal Morphological Reinflection,0,0,0.0,0.0
D18-1023,Multi-lingual Common Semantic Space Construction via Cluster-consistent Word Embedding,2018,31,1,2,0,9579,lifu huang,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,0.04697450568241884,-0.07905445401611207
D18-1035,A Stable and Effective Learning Strategy for Trainable Greedy Decoding,2018,37,4,3,0,8634,yun chen,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,1.1080157586354353,0.5223288034787641
D18-1149,Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement,2018,0,48,3,1,10266,jason lee,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,0.0,0.0
D18-1176,Dynamic Meta-Embeddings for Improved Sentence Representations,2018,0,2,3,0,89,douwe kiela,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,0.2776337335288787,-0.19511070700392805
D18-1398,Meta-Learning for Low-Resource Neural Machine Translation,2018,0,17,5,1,7512,jiatao gu,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,0.18602794150012567,-0.25320349094068173
D18-1527,Conditional Word Embedding and Hypothesis Testing via {B}ayes-by-Backprop,2018,0,3,4,0,4843,rujun han,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,-0.15096055025368058,-0.3076206026653791
D18-1544,Grammar Induction with Neural Language Models: An Unusual Replication,2018,0,14,2,0,12837,phu htut,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,0.3089085751024246,-0.8413303251870011
W17-5409,{S}trawman: An Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis,2017,6,1,1,1,1032,kyunghyun cho,Proceedings of the First Workshop on Building Linguistically Generalizable {NLP} Systems,0,0,-0.4164963964958969,-0.02848699130940175
W17-4806,Neural Machine Translation for Cross-Lingual Pronoun Prediction,2017,0,3,4,1,14551,sebastien jean,Proceedings of the Third Workshop on Discourse in Machine Translation,0,0,0.15482357209431644,-0.6189079818993686
Q17-1026,Fully Character-Level Neural Machine Translation without Explicit Segmentation,2017,2,144,2,1,10266,jason lee,Transactions of the Association for Computational Linguistics,0,0,0.27472061520526825,-1.231660281910604
P17-2012,Learning to Parse and Translate Improves Neural Machine Translation,2017,20,50,3,0,294,akiko eriguchi,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,0,0.44281537661967674,-1.4513183959562934
E17-3017,{N}ematus: a Toolkit for Neural Machine Translation,2017,5,124,3,0,2690,rico sennrich,Proceedings of the Software Demonstrations of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,0,0.18602794150012567,-0.25320349094068173
E17-1099,Learning to Translate in Real-time with Neural Machine Translation,2017,8,23,3,1,7512,jiatao gu,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,0,0.6818832713075822,-1.9268181013880534
D17-1061,Task-Oriented Query Reformulation with Reinforcement Learning,2017,0,18,2,0,3155,rodrigo nogueira,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,0,-0.031362483355824,-0.032453646393453
D17-1210,Trainable Greedy Decoding for Neural Machine Translation,2017,0,13,2,1,7512,jiatao gu,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,0,0.18602794150012567,-0.25320349094068173
W16-2309,{NYU}-{MILA} Neural Machine Translation Systems for {WMT}{'}16,2016,11,5,2,0,33882,junyoung chung,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,0,1.2566439458364618,-1.330436599135372
W16-1618,A Two-stage Approach for Extending Event Detection to New Types via Neural Networks,2016,28,13,3,0,118,thien nguyen,Proceedings of the 1st Workshop on Representation Learning for {NLP},0,0,0.0,0.0
Q16-1002,Learning to Understand Phrases by Embedding the Dictionary,2016,33,45,2,0,27140,felix hill,Transactions of the Association for Computational Linguistics,0,0,-0.41356136174419145,0.5049782485896277
P16-5005,Neural Machine Translation,2016,16,36,2,0,34356,thang luong,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,0,0,0.19128917383513414,-0.5429751669037561
P16-1125,Larger-Context Language Modelling with Recurrent Neural Network,2016,36,21,2,0,20813,tian wang,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,0,0.1377114891375804,-0.6684833295401224
P16-1160,A Character-level Decoder without Explicit Segmentation for Neural Machine Translation,2016,37,147,2,0,33882,junyoung chung,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,0,0.6365750054266899,0.14987602337903952
N16-1034,Joint Event Extraction via Recurrent Neural Networks,2016,29,86,2,0,118,thien nguyen,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,0,0.0,0.0
N16-1101,"Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism",2016,19,127,2,1,3511,orhan firat,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,0,0.4323629122972387,-1.5926119366392189
N16-1162,Learning Distributed Representations of Sentences from Unlabelled Data,2016,34,131,2,0,27140,felix hill,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,0,0.3056328182831567,-0.2676404270185911
D16-1026,Zero-Resource Translation with Multi-Lingual Neural Machine Translation,2016,25,23,5,1,3511,orhan firat,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,0,0.8521749346911758,-1.5854033415409337
D16-1209,Gated Word-Character Recurrent Language Model,2016,21,29,2,0,35604,yasumasa miyamoto,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,0,-0.05600143163418515,-0.07450354818285555
C16-1011,A Correlational Encoder Decoder Architecture for Pivot Based Sequence Generation,2016,31,7,5,0,25404,amrita saha,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,0,-0.060136862120684226,-0.3184738685580416
W15-3014,{M}ontreal Neural Machine Translation Systems for {WMT}{'}15,2015,20,70,3,1,14551,sebastien jean,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,0,0.097138501029235,-0.20765347728454053
P15-1001,On Using Very Large Target Vocabulary for Neural Machine Translation,2015,20,437,2,1,14551,sebastien jean,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,0,0.14595769074621942,-1.135056768719804
W14-4009,Overcoming the Curse of Sentence Length for Neural Machine Translation using Automatic Segmentation,2014,1,20,4,0,38507,jean pougetabadie,"Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,0,0.6299450707563484,-1.54142203037383
W14-4012,On the Properties of Neural Machine Translation: Encoder{--}Decoder Approaches,2014,9,1012,1,1,1032,kyunghyun cho,"Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,0,0.4310122594228069,-1.149521071020984
D14-1179,Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation,2014,31,2281,1,1,1032,kyunghyun cho,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,0,0.24456229026398799,-0.3063689496430935
